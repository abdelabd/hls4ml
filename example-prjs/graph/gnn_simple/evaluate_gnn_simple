#!/usr/bin/env python                                                                                                             
import networkx as nx
import numpy as np

from graph_nets import utils_np, utils_tf

from heptrkx import load_yaml
from heptrkx.nx_graph import utils_plot, utils_data, utils_train, prepare, utils_test
from heptrkx.postprocess import wrangler, analysis, inference
from heptrkx import master

import os
import glob
import argparse
import sys

if __name__ == "__main__":

    parser = argparse.ArgumentParser(description='evalute GNN models')
    add_arg = parser.add_argument
    add_arg('config', help='configuration file for training')
    add_arg('evtid', type=int, help='event ID')
    add_arg('--iteration',  type=int, default=-1)
    add_arg('--ckpt', default=None)

    args = parser.parse_args()
    evtid = args.evtid
    iteration = args.iteration
    input_ckpt = args.ckpt

    from heptrkx.postprocess.evaluate_tf import create_evaluator

    config_file = args.config
    config = load_yaml(config_file)
    file_dir = config['make_graph']['out_graph']
    hits_graph_dir = config['data']['input_hitsgraph_dir']
    trk_dir = config['track_ml']['dir']
    if input_ckpt is None:
        input_ckpt = os.path.join(config['segment_training']['output_dir'],
                                  config['segment_training']['prod_name'])

    file_names = [os.path.join(file_dir, "event000001000_g000000000_INPUT.npz")]
    true_features = ['pt', 'particle_id', 'nhits']
    batch_size = 1

    n_batches = 1

    event = master.Event(trk_dir, evtid)
    hits = event.hits
    truth = event.truth
    model, model_c, sess = create_evaluator(config_file, iteration, input_ckpt)

    all_graphs = []
    is_digraph = True
    is_bidirection = False
    # evaluate each graph                                                                                                        

    input_graphs = []
    target_graphs = []
    file_name = file_names[0]
    with np.load(file_name) as f:
        input_graphs.append(dict(f.items()))

    with np.load(file_name.replace("INPUT", "TARGET")) as f:
        target_graphs.append(dict(f.items()))

    graphs = model(utils_np.data_dicts_to_graphs_tuple(input_graphs),
                   utils_np.data_dicts_to_graphs_tuple(target_graphs),
                   use_digraph=is_digraph, bidirection=is_bidirection)

    I = input_graphs[0]
    G = graphs[0]

    nodes = I['nodes']
    edges = I['edges']
    receivers = I['receivers']
    senders = I['senders']
    globs = I['globals']
    n_nodes = nodes.shape[0]
    n_edges = edges.shape[0]


    predict = np.array([G.edges[edge]['predict'][0] for edge in G.edges()])

    print('input node features:')
    print(' shape:', nodes.shape)
    print(' values:', nodes)
    print()
    print('input edge features:')
    print(' shape:', edges.shape)
    print(' values:', edges)
    print()
    print('input global features:')
    print(' shape:', globs.shape)
    print(' values:', globs)
    print()
    print('input receivers:')
    print(' shape:', receivers.shape)
    print(' values:', receivers)
    print()
    print('input senders:')
    print(' shape:', senders.shape)
    print(' values:', senders)
    print()
    print('predicted edge weights:')
    print(' shape:', predict.shape)
    print(' values:', predict)

    core_edge_weights = []
    core_edge_biases = []
    core_node_weights = []
    core_node_biases = []
    for layer in model_c._core._edge_block._edge_model._layers:
        for sublayer in layer._layers:
            core_edge_weights.append(sublayer._w.eval(session=sess))
            core_edge_biases.append(sublayer._b.eval(session=sess))
    for layer in model_c._core._node_block._node_model._layers:
        for sublayer in layer._layers:
            core_node_weights.append(sublayer._w.eval(session=sess))
            core_node_biases.append(sublayer._b.eval(session=sess))

    encoder_edge_biases = []
    encoder_edge_weights = []
    encoder_node_biases = []
    encoder_node_weights = []
    decoder_edge_biases = []
    decoder_edge_weights = []
    #output_edge_biases = []
    #output_edge_weights = []
    for v in model_c._encoder._network._edge_model.trainable_variables:
        if 'b:0' in v.name:
            encoder_edge_biases.append(v.eval(session=sess))
        elif 'w:0' in v.name:
            encoder_edge_weights.append(v.eval(session=sess))
    for v in model_c._encoder._network._node_model.trainable_variables:
        if 'b:0' in v.name:
            encoder_node_biases.append(v.eval(session=sess))
        elif 'w:0' in v.name:
            encoder_node_weights.append(v.eval(session=sess))
    for v in model_c._decoder._edge_model.trainable_variables:
        if 'b:0' in v.name:
            decoder_edge_biases.append(v.eval(session=sess))
        elif 'w:0' in v.name:
            decoder_edge_weights.append(v.eval(session=sess))
    for v in model_c._output_transform._edge_model.trainable_variables:
        if 'b:0' in v.name:
            decoder_edge_biases.append(v.eval(session=sess))
        elif 'w:0' in v.name:
            decoder_edge_weights.append(v.eval(session=sess))

    print()
    print('model:')
    print()

    for i, (w, b) in enumerate(zip(encoder_node_weights, encoder_node_biases)):
        print('encoder node weights layer {}:'.format(i))
        print(' shape:', w.shape)
        print(' values:', w)
        print()
        print('encoder node biases layer {}:'.format(i))
        print(' shape:', b.shape)
        print(' values:', b)
        print()

    for i, (w, b) in enumerate(zip(encoder_edge_weights, encoder_edge_biases)):
        print('encoder edge weights layer {}:'.format(i))
        print(' shape:', w.shape)
        print(' values:', w)
        print()
        print('encoder edge biases layer {}:'.format(i))
        print(' shape:', b.shape)
        print(' values:', b)
        print()

    for i, (w, b) in enumerate(zip(core_edge_weights, core_edge_biases)):
        print('core edge weights layer {}:'.format(i))
        print(' shape:', w.shape)
        print(' values:', w)
        print()
        print('core edge biases layer {}:'.format(i))
        print(' shape:', b.shape)
        print(' values:', b)
        print()

    for i, (w, b) in enumerate(zip(core_node_weights, core_node_biases)):
        print('core node weights layer {}:'.format(i))
        print(' shape:', w.shape)
        print(' values:', w)
        print()
        print('core node biases layer {}:'.format(i))
        print(' shape:', b.shape)
        print(' values:', b)
        print()

    for i, (w, b) in enumerate(zip(decoder_edge_weights, decoder_edge_biases)):
        print('decoder edge weights layer {}:'.format(i))
        print(' shape:', w.shape)
        print(' values:', w)
        print()
        print('decoder edge biases layer {}:'.format(i))
        print(' shape:', b.shape)
        print(' values:', b)
        print()
    """
    for i, (w, b) in enumerate(zip(output_edge_weights, output_edge_biases)):
        print('output edge weights layer {}:'.format(i))
        print(' shape:', w.shape)
        print(' values:', w)
        print()
        print('output edge biases layer {}:'.format(i))
        print(' shape:', b.shape)
        print(' values:', b)
        print()
    """
    print('evaulate by hand:')
    print()
    print('input nodes shape:', nodes.shape)
    print('input edges shape:', edges.shape)
    print()

    #print('ENCODING NODES')#HLS
    n = nodes.dot(encoder_node_weights[0])
    #print('nodes', nodes.shape)#HLS
    #print('encoder_node_weights[0]', encoder_node_weights[0].shape)#HLS
    n += encoder_node_biases[0]
    #print('encoder_node_biases[0]', encoder_node_biases[0].shape)#HLS
    #print('n', n.shape)#HLS
    n = np.maximum(0,n)
    n = n.dot(encoder_node_weights[1])
    #print('encoder_node_weights[1]', encoder_node_weights[1].shape)#HLS
    n += encoder_node_biases[1]
    #print('encoder_node_biases[1]', encoder_node_biases[1].shape)#HLS
    n = np.maximum(0,n)
    #print('n before', n.shape)#HLS
    #print()#HLS

    #print('ENCODING EDGES')#HLS
    e = edges.dot(encoder_edge_weights[0])
    #print('edges', edges.shape)#HLS
    #print('encoder_edge_weights[0]', encoder_edge_weights[0].shape)#HLS
    e += encoder_edge_biases[0]
    #print('encoder_edge_biases[0]', encoder_edge_biases[0].shape)#HLS
    e = np.maximum(0,e)
    e = e.dot(encoder_edge_weights[1])
    #print('encoder_edge_weights[1]', encoder_edge_weights[1].shape)#HLS
    e += encoder_edge_biases[1]
    #print('encoder_edge_biases[1]', encoder_edge_biases[1].shape)#HLS
    e = np.maximum(0,e)
    #print('e before', e.shape)#HLS
    #print()#HLS

    print('nodes shape after encoder:', n.shape)
    print('edges shape after encoder:', e.shape)
    print()
    print('Rn = ', n)
    print()
    print('Re = ', e)
    print()

    n0 = n
    e0 = e

    #print('CORE Graph Network')#HLS
    #print('config[segment_training][parameters][n_iters]', config['segment_training']['parameters']['n_iters']) #HLS
    for _ in range(config['segment_training']['parameters']['n_iters']):
        core_input_n = n #np.concatenate([n0, n], axis=1)
        core_input_e = e #np.concatenate([e0, e], axis=1)

        print("""'nodes shape after core concat:'"""'core_input_n', core_input_n.shape)
        print("""'edges shape after core concat:'"""'core_input_e', core_input_e.shape)
        #print()
        nodes_receive = np.zeros((n_nodes,core_edge_biases[1].shape[0]))
        edges_update = np.zeros((n_edges,core_edge_biases[1].shape[0]))
        #print('nodes_receive before', nodes_receive.shape) #HLS
        #print('edges_update before', edges_update.shape) #HLS
        #print('core_edge_weights[0]', core_edge_weights[0].shape) #HLS
        #print('core_edge_biases[0]', core_edge_biases[0].shape)#HLS
        #print('core_edge_weights[1]', core_edge_weights[1].shape) #HLS
        #print('core_edge_biases[1]', core_edge_biases[1].shape) #HLS
        #print('receivers', receivers.shape)#HLS
        #print('senders', senders.shape)#HLS
        #print()#HLS
        for k, (r, s) in enumerate(zip(receivers, senders)):
            l = np.concatenate([core_input_e[k],core_input_n[r],core_input_n[s]])
            l = l.dot(core_edge_weights[0])
            l += core_edge_biases[0]
            l = np.maximum(0,l)
            l = l.dot(core_edge_weights[1])
            l += core_edge_biases[1]
            l = np.maximum(0,l)
            edges_update[k] = l
            nodes_receive[r] += l
            #print('edges_update[k] = l', l.shape)#HLS
            #print('nodes_receive[r]', nodes_receive[r].shape)#HLS

        #print()#HLS
        #print('nodes_receive after', nodes_receive.shape)#HLS
        #print('edges_update after', edges_update.shape)#HLS
        #print()#HLS
        nodes_update = np.zeros((n_nodes,core_node_biases[1].shape[0]))
        #print('nodes_update before', nodes_update.shape) #HLS
        #print('core_node_weights[0]', core_node_weights[0].shape) #HLS
        #print('core_node_weights[1]', core_node_weights[1].shape) #HLS
        for i in range(n_nodes):
            l = np.concatenate([nodes_receive[i], core_input_n[i]])
            l = l.dot(core_node_weights[0])
            l += core_node_biases[0]
            l = np.maximum(0,l)
            l = l.dot(core_node_weights[1])
            l += core_node_biases[1]
            l = np.maximum(0,l)
            nodes_update[i] = l

        n = nodes_update
        e = edges_update
        #print('n after', n.shape)#HLS
        #print('e after', e.shape)#HLS
        #print() #HLS

    print('nodes shape after core update:', n.shape)
    print('edges shape after core update:', e.shape)
    print()

    #print('DECODING EDGES')#HLS
    e = e.dot(decoder_edge_weights[0])
    #print('decoder_edge_weights[0]', decoder_edge_weights[0].shape)#HLS
    e += decoder_edge_biases[0]
    #print('decoder_edge_biases[0]', decoder_edge_biases[0].shape)#HLS
    e = np.maximum(0,e)
    #print('e intermediate', e.shape)#HLS
    e = e.dot(decoder_edge_weights[1])
    #print('decoder_edge_weights[1]', decoder_edge_weights[1].shape)#HLS
    e += decoder_edge_biases[1]
    #print('decoder_edge_biases[1]', decoder_edge_biases[1].shape)#HLS
    e = np.maximum(0,e)
    
    print('edges shape after decoder:', e.shape)
    print()
    
    print('Output')
    e = e.dot(decoder_edge_weights[2])
    #print('output_edge_weights[0]', output_edge_weights[0].shape)#HLS
    e += decoder_edge_biases[2]
    #print('output_edge_biases[0]', output_edge_biases[0].shape)#HLS
    e = np.maximum(0,e)
    print('e intermediate', e.shape)
    e = e.dot(decoder_edge_weights[3])
    #print('output_edge_weights[1]', output_edge_weights[1].shape)#HLS
    e += decoder_edge_biases[3]
    #print('output_edge_biases[1]', output_edge_biases[1].shape) #HLS

    def sigmoid(x):  
        return np.exp(-np.logaddexp(0, -x))
        
    e = sigmoid(e)
    e = e.flatten()
    
    print('predicted edge weights from model:')
    print(' shape:', predict.shape)
    print(' values:', predict)
    print()
    print('predicted edge weights by hand:')
    print(' shape:', e.shape)
    print(' values:', e)
        
    # save the input and output graphs for use in test bench
    np.savetxt('tb_input_node_features.dat',nodes.reshape((1,-1)),delimiter=' ',fmt='%f')
    np.savetxt('tb_input_edge_features.dat',edges.reshape((1,-1)),delimiter=' ',fmt='%f')
    np.savetxt('tb_receivers.dat',receivers.reshape((1,-1)),delimiter=' ',fmt='%d')
    np.savetxt('tb_senders.dat',senders.reshape((1,-1)),delimiter=' ',fmt='%d')
    np.savetxt('tb_output_edge_predictions.dat',predict.reshape((1,-1)),delimiter=' ',fmt='%f')

    encoder_node_weights_t = [np.array(encoder_node_weights[0]).T.tolist(), np.array(encoder_node_weights[1]).T.tolist()]
    encoder_node_biases_t = [np.array(encoder_node_biases[0]).T.tolist(), np.array(encoder_node_biases[1]).T.tolist()]
    encoder_edge_weights_t = [np.array(encoder_edge_weights[0]).T.tolist(), np.array(encoder_edge_weights[1]).T.tolist()]
    encoder_edge_biases_t = [np.array(encoder_edge_biases[0]).T.tolist(), np.array(encoder_edge_biases[1]).T.tolist()]
    core_edge_weights_t = [np.array(core_edge_weights[0]).T.tolist(), np.array(core_edge_weights[1]).T.tolist()]
    core_edge_biases_t = [np.array(core_edge_biases[0]).T.tolist(), np.array(core_edge_biases[1]).T.tolist()]
    core_node_weights_t = [np.array(core_node_weights[0]).T.tolist(), np.array(core_node_weights[1]).T.tolist()]
    core_node_biases_t = [np.array(core_node_biases[0]).T.tolist(), np.array(core_node_biases[1]).T.tolist()]
    decoder_edge_weights_t = [np.array(decoder_edge_weights[0]).T.tolist(), np.array(decoder_edge_weights[1]).T.tolist(), np.array(decoder_edge_weights[2]).T.tolist(), np.array(decoder_edge_weights[3]).T.tolist()]
    decoder_edge_biases_t = [np.array(decoder_edge_biases[0]).T.tolist(), np.array(decoder_edge_biases[1]).T.tolist(), np.array(decoder_edge_biases[2]).T.tolist(), np.array(decoder_edge_biases[3]).T.tolist()]

    import hls4ml
    # save the weights for use in hls4ml
    print("saving weights for use in hls4ml")
    os.makedirs('./firmware/weights', exist_ok=True)
    for i, (w, b) in enumerate(zip(encoder_edge_weights_t, encoder_edge_biases_t)):
        var = hls4ml.model.hls_model.WeightVariable('encoder_edge_w%i'%i, type_name='ap_fixed<16,6>', precision='<16,6>', data=w)
        hls4ml.writer.VivadoWriter.print_array_to_cpp(None,var,'./')
        var = hls4ml.model.hls_model.WeightVariable('encoder_edge_b%i'%i, type_name='ap_fixed<16,6>', precision='<16,6>', data=b)
        hls4ml.writer.VivadoWriter.print_array_to_cpp(None,var,'./')
    for i, (w, b) in enumerate(zip(core_edge_weights_t, core_edge_biases_t)):
        var = hls4ml.model.hls_model.WeightVariable('core_edge_w%i'%i, type_name='ap_fixed<16,6>', precision='<16,6>', data=w)
        hls4ml.writer.VivadoWriter.print_array_to_cpp(None,var,'./')
        var = hls4ml.model.hls_model.WeightVariable('core_edge_b%i'%i, type_name='ap_fixed<16,6>', precision='<16,6>', data=b)
        hls4ml.writer.VivadoWriter.print_array_to_cpp(None,var,'./')
    for i, (w, b) in enumerate(zip(decoder_edge_weights_t, decoder_edge_biases_t)):
        var = hls4ml.model.hls_model.WeightVariable('decoder_edge_w%i'%i, type_name='ap_fixed<16,6>', precision='<16,6>', data=w)
        hls4ml.writer.VivadoWriter.print_array_to_cpp(None,var,'./')
        var = hls4ml.model.hls_model.WeightVariable('decoder_edge_b%i'%i, type_name='ap_fixed<16,6>', precision='<16,6>', data=b)
        hls4ml.writer.VivadoWriter.print_array_to_cpp(None,var,'./')

    for i, (w, b) in enumerate(zip(encoder_node_weights_t, encoder_node_biases_t)):
        var = hls4ml.model.hls_model.WeightVariable('encoder_node_w%i'%i, type_name='ap_fixed<16,6>', precision='<16,6>', data=w)
        hls4ml.writer.VivadoWriter.print_array_to_cpp(None,var,'./')
        var = hls4ml.model.hls_model.WeightVariable('encoder_node_b%i'%i, type_name='ap_fixed<16,6>', precision='<16,6>', data=b)
        hls4ml.writer.VivadoWriter.print_array_to_cpp(None,var,'./')
    for i, (w, b) in enumerate(zip(core_node_weights_t, core_node_biases_t)):
        var = hls4ml.model.hls_model.WeightVariable('core_node_w%i'%i, type_name='ap_fixed<16,6>', precision='<16,6>', data=w)
        hls4ml.writer.VivadoWriter.print_array_to_cpp(None,var,'./')
        var = hls4ml.model.hls_model.WeightVariable('core_node_b%i'%i, type_name='ap_fixed<16,6>', precision='<16,6>', data=b)
        hls4ml.writer.VivadoWriter.print_array_to_cpp(None,var,'./')
